{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Hands-on: Build Multi-agent AI system using watsonx.ai & CrewAI"}, {"metadata": {}, "cell_type": "markdown", "source": "# Overview\nThis hands-on notebook demonstrates the concept of multiagent systems in AI, where multiple autonomous agents collaborate to achieve complex goals. The notebook employs the crewai library to create and manage a team of agents, each specialized in a specific task, using IBM watsonx LLM and other tools to execute their roles.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "# Definition of Multi-agent System\nA multiagent system is a system where multiple intelligent agents interact or work together to solve problems that are beyond the capabilities of a single agent. These agents can operate independently or collaboratively, each bringing their own expertise and capabilities to the table. In this notebook, the multiagent system is used to simulate a research and writing scenario involving two specialized agents.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "# Scenario\nThe scenario involves two agents working together to produce a detailed output on the topic of quantum computing:\n\n`Researcher Agent`: A senior AI researcher tasked with finding promising research in the field of quantum computing. This agent uses IBM watsonx LLM and a search tool to gather information and summarize the findings.\n\n`Writer Agent`: A senior speech writer responsible for crafting an engaging keynote speech based on the research provided by the Researcher Agent. This agent leverages the IBM watsonx LLM to structure and write the speech.\n\nThe Crew class orchestrates the workflow, coordinating the tasks and ensuring that each agent's output feeds into the next step of the process. The agents work autonomously within their defined roles, contributing to the overall objective of producing a well-researched and well-written keynote speech on quantum computing.\n"}, {"metadata": {}, "cell_type": "code", "source": "# Install library\n!pip install crewai==0.22.5\n!pip install crewai-tools==0.0.15\n!pip install langchain-ibm==0.1.3", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Import libraries\nimport os\nimport warnings\n\nfrom crewai import Crew, Task, Agent\nfrom crewai_tools import SerperDevTool\nfrom langchain_ibm import WatsonxLLM\n\nwarnings.filterwarnings(\"ignore\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Get your Serper API Key here: https://serper.dev/api-key"}, {"metadata": {}, "cell_type": "code", "source": "os.environ[\"WATSONX_APIKEY\"] = \"<YOUR IBM CLOUD API KEY HERE>\"\nos.environ[\"SERPER_API_KEY\"] = \"<YOUR SERPER API KEY HERE>\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Primary LLM: \n- The primary LLM (llm) is used by both agents to generate text based on the tasks assigned to them. This involves producing summaries, writing detailed speeches, or other natural language generation tasks.\n- `Researcher Agent`: The researcher agent uses the primary LLM to generate summaries of the research findings. For instance, when the agent is tasked with finding promising AI research, it processes the information using the LLM to create bullet-point summaries.\n- `Writer Agent`: The writer agent uses the primary LLM to draft the keynote speech. The LLM helps the agent structure the speech, write engaging content, and ensure coherence and flow in the text."}, {"metadata": {}, "cell_type": "markdown", "source": "## Function Calling LLM\n- The function_calling_llm is used when the agent needs to interact with external tools or perform specific functions beyond generating text. In this notebook:\n- `Researcher Agent`: The researcher agent uses the function_calling_llm when it needs to search the internet for research papers. The function calling LLM allows the agent to perform a search query using the SerperDevTool and process the results to extract relevant information.\n- `Tool Integration`: Function calling enables the agent to delegate tasks to the search tool or other integrated functionalities, executing commands or retrieving specific data that the agent can then process using the primary LLM."}, {"metadata": {}, "cell_type": "code", "source": "# Parameters\nparameters = {\"decoding_method\": \"greedy\", \n              \"max_new_tokens\": 500}\n\n# Create the first LLM\nllm = WatsonxLLM(\n    model_id=\"meta-llama/llama-3-70b-instruct\",\n    url=\"https://us-south.ml.cloud.ibm.com\",\n    params=parameters,\n    project_id=\"<YOUR WATSONX.AI PROJECT ID HERE>\",\n)\n\n# Create the function calling llm\nfunction_calling_llm = WatsonxLLM(\n    model_id=\"ibm-mistralai/merlinite-7b\",\n    url=\"https://us-south.ml.cloud.ibm.com\",\n    params=parameters,\n    project_id=\"<YOUR WATSONX.AI PROJECT ID HERE>\",\n)\n\n# Tools\nsearch = SerperDevTool()\n\n# Create the agent\nresearcher = Agent(\n    llm=llm,\n    function_calling_llm=function_calling_llm,\n    role=\"Senior AI Researcher\",\n    goal=\"Find promising research in the field of quantum computing.\",\n    backstory=\"You are a veteran quantum computing researcher with a background in modern physics.\",\n    allow_delegation=False,\n    tools=[search],\n    verbose=1,\n)\n\n# Create a task\ntask1 = Task(\n    description=\"Search the internet and find 5 examples of promising AI research.\",\n    expected_output=\"A detailed bullet point summary on each of the topics. Each bullet point should cover the topic, background and why the innovation is useful.\",\n    output_file=\"task1output.txt\",\n    agent=researcher,\n)\n\n# Create the second agent\nwriter = Agent(\n    llm=llm,\n    role=\"Senior Speech Writer\",\n    goal=\"Write engaging and witty keynote speeches from provided research.\",\n    backstory=\"You are a veteran quantum computing writer with a background in modern physics.\",\n    allow_delegation=False,\n    verbose=1,\n)\n\n# Create a task\ntask2 = Task(\n    description=\"Write an engaging keynote speech on quantum computing.\",\n    expected_output=\"A detailed keynote speech with an intro, body and conclusion.\",\n    output_file=\"task2output.txt\",\n    agent=writer,\n)\n\n# Put all together with the crew\ncrew = Crew(agents=[researcher, writer], tasks=[task1, task2], verbose=1)\nprint(crew.kickoff())", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.14", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}
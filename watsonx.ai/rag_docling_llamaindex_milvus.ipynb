{"metadata": {"kernelspec": {"display_name": "Python 3.11", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}, "colab": {"provenance": []}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# Docling Reader", "metadata": {"id": "nqiA8Wdl3DfX"}}, {"cell_type": "markdown", "source": "## Overview", "metadata": {"id": "bRsVK2kN3DfX"}}, {"cell_type": "markdown", "source": "[Docling](https://github.com/DS4SD/docling) extracts PDF, DOCX, HTML, and other document formats into a rich representation (incl. layout, tables etc.), which it can export to Markdown or JSON.\n\nDocling Reader and Docling Node Parser presented in this notebook seamlessly integrate Docling into LlamaIndex, enabling you to:\n- use various document types in your LLM applications with ease and speed, and\n- leverage Docling's rich format for advanced, document-native grounding.", "metadata": {"id": "wRHii9GC3DfX"}}, {"cell_type": "markdown", "source": "## Setup", "metadata": {"id": "nNzgHMRd3DfY"}}, {"cell_type": "code", "source": "%pip install -q --progress-bar off --no-warn-conflicts llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-readers-file python-dotenv\n\n!pip install -qU llama-index-embeddings-ibm llama-index-llms-ibm\n\n%pip install llama-index-vector-stores-milvus \n%pip install pymilvus>=2.4.2", "metadata": {"id": "LIvGCdvX3DfY"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "import os\n\nos.environ[\"WATSONX_APIKEY\"] = \"<REPLACE_WITH_API_KEY>\"\nPROJECT_ID = \"a62d3ee3-e744-4bf0-8eaf-cfddd415f62e\"", "metadata": {"id": "d8bb5d15-154b-4372-8932-459713883664"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "We can now define the main parameters:", "metadata": {"id": "SqsEujUV3DfZ"}}, {"cell_type": "code", "source": "import os\nfrom dotenv import load_dotenv\nfrom llama_index.embeddings.ibm import WatsonxEmbeddings\nfrom llama_index.llms.ibm import WatsonxLLM\n\n# embedding model params\ntruncate_input_tokens = 512\n\n# llm params\ntemperature = 0.5\nmax_new_tokens = 2000\nadditional_params = {\n    \"decoding_method\": \"sample\",\n    \"min_new_tokens\": 1,\n    \"top_k\": 50,\n    \"top_p\": 1,\n}\n\nload_dotenv()\nEMBED_MODEL = WatsonxEmbeddings(\n    model_id=\"intfloat/multilingual-e5-large\",\n    url=\"https://us-south.ml.cloud.ibm.com\",\n    project_id=PROJECT_ID,\n    truncate_input_tokens=truncate_input_tokens,\n)\n\nGEN_MODEL = WatsonxLLM(\n    model_id=\"mistralai/mistral-large\",\n    url=\"https://us-south.ml.cloud.ibm.com\",\n    project_id=PROJECT_ID,\n    temperature=temperature,\n    max_new_tokens=max_new_tokens,\n    additional_params=additional_params,\n)\n", "metadata": {"id": "pGk7My2W3DfZ"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "SOURCE = \"https://www.btpn.com/pdf/investor/laporan-keberlanjutan/2024/laporan--keberlanjutan--bank--btpn--tahun-2023_-final.pdf\"\nQUERY=\"Tampilkan tabel lengkap Jumlah Total Karyawan Berdasarkan Kontrak Kerja Kepegawaian, Berdasarkan Jenis Kelamin\"", "metadata": {"id": "73f3b3d3-0700-4b49-b99a-7e8e0a754221"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## Using Markdown export", "metadata": {"id": "WYurSk853Dfa"}}, {"cell_type": "markdown", "source": "To create a simple RAG pipeline, we can:\n- define a `DoclingReader`, which by default exports to Markdown, and\n- use a standard node parser for these Markdown-based docs, e.g. a `MarkdownNodeParser`", "metadata": {"id": "fb0lxn_r3Dfa"}}, {"cell_type": "code", "source": "from llama_index.core import VectorStoreIndex\nfrom llama_index.core.node_parser import MarkdownNodeParser\nfrom llama_index.readers.docling import DoclingReader\nfrom llama_index.core import VectorStoreIndex, StorageContext\nfrom llama_index.vector_stores.milvus import MilvusVectorStore\n\n\nvector_store = MilvusVectorStore(\n    uri=\"./milvus_demo_1.db\", \n    dim=1024, \n    overwrite=True,\n    hybrid_ranker=\"RRFRanker\",\n    hybrid_ranker_params={\"k\": 60},\n)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n\nreader = DoclingReader()\nnode_parser = MarkdownNodeParser()\n\nindex = VectorStoreIndex.from_documents(\n    documents=reader.load_data(SOURCE),\n    transformations=[node_parser],\n    embed_model=EMBED_MODEL,\n    storage_context=storage_context\n)\n", "metadata": {"id": "oNXGVP3N3Dfa", "outputId": "bb982001-5bab-4657-b0f4-5ae59c01f164"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "from IPython.display import display, Markdown, Latex\n\nresult = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\")\n\nprint(f\"\\nAnswer:\")\ndisplay(Markdown(result.response.strip()))\n\nprint(f\"\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])\n", "metadata": {"id": "5ff40a4b-37e4-43bb-a26a-809734cd2ad2"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## Using Docling format", "metadata": {"id": "mo1Wdcwq3Dfa"}}, {"cell_type": "markdown", "source": "To leverage Docling's rich native format, we:\n- create a `DoclingReader` with JSON export type, and\n- employ a `DoclingNodeParser` in order to appropriately parse that Docling format.\n\nNotice how the sources now also contain document-level grounding (e.g. page number or bounding box information):", "metadata": {"id": "xdvU0Lvk3Dfa"}}, {"cell_type": "code", "source": "from llama_index.node_parser.docling import DoclingNodeParser\n\nreader = DoclingReader(export_type=DoclingReader.ExportType.JSON)\nnode_parser = DoclingNodeParser()\n\nindex = VectorStoreIndex.from_documents(\n    documents=reader.load_data(SOURCE),\n    transformations=[node_parser],\n    embed_model=EMBED_MODEL,\n    storage_context=storage_context\n)", "metadata": {"id": "KFvd7KUR3Dfb", "outputId": "9527ce6b-87cb-4419-f77f-210464d21b23"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "result = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])", "metadata": {"id": "9b626f99-6783-4e75-a835-71f6cd8e2a10"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## With Simple Directory Reader", "metadata": {"id": "TZteQpsc3Dfb"}}, {"cell_type": "markdown", "source": "To demonstrate this usage pattern, we first set up a test document directory.", "metadata": {"id": "gG6fYGL93Dfb"}}, {"cell_type": "code", "source": "from pathlib import Path\nfrom tempfile import mkdtemp\nimport requests\n\ntmp_dir_path = Path(mkdtemp())\nr = requests.get(SOURCE)\nwith open(tmp_dir_path / f\"{Path(SOURCE).name}.pdf\", \"wb\") as out_file:\n    out_file.write(r.content)", "metadata": {"id": "qSUYKCLg3Dfb"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "Using the `reader` and `node_parser` definitions from any of the above variants, usage with `SimpleDirectoryReader` then looks as follows:", "metadata": {"id": "WkLyus9l3Dfb"}}, {"cell_type": "code", "source": "from llama_index.core import SimpleDirectoryReader\n\ndir_reader = SimpleDirectoryReader(\n    input_dir=tmp_dir_path,\n    file_extractor={\".pdf\": reader},\n)\n\nindex = VectorStoreIndex.from_documents(\n    documents=dir_reader.load_data(SOURCE),\n    transformations=[node_parser],\n    embed_model=EMBED_MODEL,\n)", "metadata": {"id": "CiG9XRtY3Dfb", "outputId": "1e13dd55-1db4-42a1-a6b2-985c95334b5b"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "result = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])", "metadata": {"id": "fb5cd6c1-3b28-4043-a5ea-45810f20d16a"}, "outputs": [], "execution_count": null}]}
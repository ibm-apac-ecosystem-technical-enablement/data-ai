{"cells":[{"cell_type":"markdown","metadata":{"id":"nqiA8Wdl3DfX"},"source":["# Docling Reader"]},{"cell_type":"markdown","metadata":{"id":"bRsVK2kN3DfX"},"source":["## Overview"]},{"cell_type":"markdown","metadata":{"id":"wRHii9GC3DfX"},"source":["[Docling](https://github.com/DS4SD/docling) extracts PDF, DOCX, HTML, and other document formats into a rich representation (incl. layout, tables etc.), which it can export to Markdown or JSON.\n","\n","Docling Reader and Docling Node Parser presented in this notebook seamlessly integrate Docling into LlamaIndex, enabling you to:\n","- use various document types in your LLM applications with ease and speed, and\n","- leverage Docling's rich format for advanced, document-native grounding."]},{"cell_type":"markdown","metadata":{"id":"nNzgHMRd3DfY"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LIvGCdvX3DfY"},"outputs":[],"source":["%pip install -q --progress-bar off --no-warn-conflicts llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-readers-file python-dotenv\n","\n","!pip install -qU llama-index-embeddings-ibm llama-index-llms-ibm\n","\n","%pip install llama-index-vector-stores-milvus \n","%pip install pymilvus>=2.4.2"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"d8bb5d15-154b-4372-8932-459713883664"},"outputs":[],"source":["import os\n","\n","os.environ[\"WATSONX_APIKEY\"] = \"<REPLACE WITH YOUR OWN API KEY>\"\n","PROJECT_ID = \"<REPLACE WITH YOUR OWN PROJECT ID>\""]},{"cell_type":"markdown","metadata":{"id":"SqsEujUV3DfZ"},"source":["We can now define the main parameters:"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"pGk7My2W3DfZ"},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","from llama_index.embeddings.ibm import WatsonxEmbeddings\n","from llama_index.llms.ibm import WatsonxLLM\n","\n","# embedding model params\n","truncate_input_tokens = 512\n","\n","# llm params\n","temperature = 0.5\n","max_new_tokens = 2000\n","additional_params = {\n","    \"decoding_method\": \"sample\",\n","    \"min_new_tokens\": 1,\n","    \"top_k\": 50,\n","    \"top_p\": 1,\n","}\n","\n","load_dotenv()\n","EMBED_MODEL = WatsonxEmbeddings(\n","    model_id=\"intfloat/multilingual-e5-large\",\n","    url=\"https://us-south.ml.cloud.ibm.com\",\n","    project_id=PROJECT_ID,\n","    truncate_input_tokens=truncate_input_tokens,\n",")\n","\n","GEN_MODEL = WatsonxLLM(\n","    model_id=\"mistralai/mistral-large\",\n","    url=\"https://us-south.ml.cloud.ibm.com\",\n","    project_id=PROJECT_ID,\n","    temperature=temperature,\n","    max_new_tokens=max_new_tokens,\n","    additional_params=additional_params,\n",")\n","\n","SOURCE = \"https://badanbahasa.kemdikbud.go.id/lamanbahasa/sites/default/files/PUEBI.pdf\"  # Docling Technical Report\n","QUERY = \"Bilakah Tanda titik dua akan dipakaikan?\""]},{"cell_type":"markdown","metadata":{"id":"WYurSk853Dfa"},"source":["## Using Markdown export"]},{"cell_type":"markdown","metadata":{"id":"fb0lxn_r3Dfa"},"source":["To create a simple RAG pipeline, we can:\n","- define a `DoclingReader`, which by default exports to Markdown, and\n","- use a standard node parser for these Markdown-based docs, e.g. a `MarkdownNodeParser`"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"oNXGVP3N3Dfa","outputId":"bb982001-5bab-4657-b0f4-5ae59c01f164"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5bf59a2585684a5aa0591689f2cf3117","version_major":2,"version_minor":0},"text/plain":["Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Q: Bilakah Tanda titik dua akan dipakaikan?\n","A: 1. Tanda titik dua dipakai pada akhir suatu pernyataan lengkap yang diikuti pemerincian atau penjelasan.\n","\n","Sources:\n"]},{"data":{"text/plain":["[('## D. Tanda Titik Dua (:)\\n\\n- 1. Tanda titik dua dipakai pada akhir suatu pernyataan lengkap yang diikuti pemerincian atau penjelasan.',\n","  {'header_path': '/PED@ManuMuM BIAAn BAHASA ID@NESIA/'}),\n"," ('## Misalnya:\\n\\nMereka memerlukan perabot rumah tangga: kursi, meja, dan lemari.\\n\\nHanya ada dua pilihan bagi para pejuang kemerdekaan: hidup atau mati.\\n\\n- 2. Tanda titik dua tidak dipakai jika perincian atau penjelasan itu merupakan pelengkap yang mengakhiri pernyataan.',\n","  {'header_path': '/PED@ManuMuM BIAAn BAHASA ID@NESIA/'})]"]},"metadata":{},"output_type":"display_data"}],"source":["from llama_index.core import VectorStoreIndex\n","from llama_index.core.node_parser import MarkdownNodeParser\n","from llama_index.readers.docling import DoclingReader\n","from llama_index.core import VectorStoreIndex, StorageContext\n","from llama_index.vector_stores.milvus import MilvusVectorStore\n","\n","\n","vector_store = MilvusVectorStore(\n","    uri=\"./milvus_demo_1.db\", \n","    dim=1024, \n","    overwrite=True,\n","    hybrid_ranker=\"RRFRanker\",\n","    hybrid_ranker_params={\"k\": 60},\n",")\n","storage_context = StorageContext.from_defaults(vector_store=vector_store)\n","\n","reader = DoclingReader()\n","node_parser = MarkdownNodeParser()\n","\n","index = VectorStoreIndex.from_documents(\n","    documents=reader.load_data(SOURCE),\n","    transformations=[node_parser],\n","    embed_model=EMBED_MODEL,\n","    storage_context=storage_context\n",")\n","result = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\n","print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\n","display([(n.text, n.metadata) for n in result.source_nodes])"]},{"cell_type":"markdown","metadata":{"id":"mo1Wdcwq3Dfa"},"source":["## Using Docling format"]},{"cell_type":"markdown","metadata":{"id":"xdvU0Lvk3Dfa"},"source":["To leverage Docling's rich native format, we:\n","- create a `DoclingReader` with JSON export type, and\n","- employ a `DoclingNodeParser` in order to appropriately parse that Docling format.\n","\n","Notice how the sources now also contain document-level grounding (e.g. page number or bounding box information):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFvd7KUR3Dfb","outputId":"9527ce6b-87cb-4419-f77f-210464d21b23"},"outputs":[],"source":["from llama_index.node_parser.docling import DoclingNodeParser\n","\n","reader = DoclingReader(export_type=DoclingReader.ExportType.JSON)\n","node_parser = DoclingNodeParser()\n","\n","index = VectorStoreIndex.from_documents(\n","    documents=reader.load_data(SOURCE),\n","    transformations=[node_parser],\n","    embed_model=EMBED_MODEL,\n","    storage_context=storage_context\n",")\n","result = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\n","print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\n","display([(n.text, n.metadata) for n in result.source_nodes])"]},{"cell_type":"markdown","metadata":{"id":"TZteQpsc3Dfb"},"source":["## With Simple Directory Reader"]},{"cell_type":"markdown","metadata":{"id":"gG6fYGL93Dfb"},"source":["To demonstrate this usage pattern, we first set up a test document directory."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qSUYKCLg3Dfb"},"outputs":[],"source":["from pathlib import Path\n","from tempfile import mkdtemp\n","import requests\n","\n","tmp_dir_path = Path(mkdtemp())\n","r = requests.get(SOURCE)\n","with open(tmp_dir_path / f\"{Path(SOURCE).name}.pdf\", \"wb\") as out_file:\n","    out_file.write(r.content)"]},{"cell_type":"markdown","metadata":{"id":"WkLyus9l3Dfb"},"source":["Using the `reader` and `node_parser` definitions from any of the above variants, usage with `SimpleDirectoryReader` then looks as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CiG9XRtY3Dfb","outputId":"1e13dd55-1db4-42a1-a6b2-985c95334b5b"},"outputs":[],"source":["from llama_index.core import SimpleDirectoryReader\n","\n","dir_reader = SimpleDirectoryReader(\n","    input_dir=tmp_dir_path,\n","    file_extractor={\".pdf\": reader},\n",")\n","\n","index = VectorStoreIndex.from_documents(\n","    documents=dir_reader.load_data(SOURCE),\n","    transformations=[node_parser],\n","    embed_model=EMBED_MODEL,\n",")\n","result = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\n","print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\n","display([(n.text, n.metadata) for n in result.source_nodes])"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.11","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}

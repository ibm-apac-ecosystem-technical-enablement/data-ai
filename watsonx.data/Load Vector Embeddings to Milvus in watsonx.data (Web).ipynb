{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97254177-6aa1-44a4-986a-389d32cd5c84",
   "metadata": {},
   "source": [
    "# Load Vector Embeddings to Milvus in watsonx.data (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc29d5-76b4-4c9c-abdd-eaf8b4c00ebf",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This Jupyter Notebook provides a step-by-step guide on how to prepare document data for RAG using Milvus (in watsonx.data as a vector database).\n",
    "\n",
    "In this notebook, we will convert text to vector embeddings and store the embeddings to Milvus as a vector database (in watsonx.data). Here are the steps:\n",
    "1. Install and import libraries.\n",
    "2. Connect to watsonx.data.\n",
    "3. Connect to Milvus.\n",
    "4. Create a Collection in Milvus.\n",
    "5. Insert Vectors into Milvus.\n",
    "6. Query Docs from Milvus through Semantic Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2181680-a94f-42c2-a79a-68b10c29422f",
   "metadata": {},
   "source": [
    "- Author: ahmad.muzaffar@ibm.com (APAC Ecosystem Technical Enablement).\n",
    "- This material has been adopted from material originally produced by Katherine Ciaravalli, Ken Bailey and George Baklarz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae50a6",
   "metadata": {},
   "source": [
    "## 1. Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1010b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install wikipedia\n",
    "!pip install pymilvus\n",
    "!pip install sentence_transformers\n",
    "!pip install grpcio==1.60.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf09ccd-d7ba-4ff6-8180-ed2bae28c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pymilvus import Collection, connections\n",
    "from pymilvus import utility\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ae98b-4c1c-47be-a39d-7841b6cc5002",
   "metadata": {},
   "source": [
    "## 1. Connect to watsonx.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65d50e-d9ff-41c6-bca3-5578fa4e3d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f /tmp/presto.cert\n",
    "!echo QUIT | openssl s_client -showcerts -connect localhost:8443 | awk '/-----BEGIN CERTIFICATE-----/ {p=1}; p; /-----END CERTIFICATE-----/ {p=0}' > /tmp/presto.crt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e2ce4-f668-485b-a4eb-0c8c59b0e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run presto.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c1b33-0deb-49b0-88f8-69b05ebb9084",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "   connect\n",
    "   userid=ibmlhadmin\n",
    "   password=password\n",
    "   hostname=watsonxdata\n",
    "   port=8443\n",
    "   catalog=tpch\n",
    "   schema=tiny\n",
    "   certfile=/certs/lh-ssl-ts.crt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae179cac-13b8-4856-91da-2fbaadabe7be",
   "metadata": {},
   "source": [
    "## 2. Connect to Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1213aa8-d2bc-40f7-b049-4818e0b88626",
   "metadata": {},
   "source": [
    "#### Milvus Connection Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37cc34f-8962-4f94-b533-2b5719dd76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "host            = 'watsonxdata'\n",
    "port            = 19530\n",
    "user            = 'ibmlhadmin'\n",
    "password        = 'password'\n",
    "server_pem_path = '/tmp/presto.crt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5954387-046a-4f3d-a41e-a9bff19c979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Connection to Milvus\n",
    "from pymilvus import(\n",
    "    Milvus,\n",
    "    IndexType,\n",
    "    Status,\n",
    "    connections,\n",
    "    FieldSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    ")\n",
    "\n",
    "connections.connect(alias='default',\n",
    "                   host=host,\n",
    "                   port=port,\n",
    "                   user=user,\n",
    "                   password=password,\n",
    "                   server_pem_path=server_pem_path,\n",
    "                   server_name='watsonxdata',\n",
    "                   secure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d49fa-8275-403c-962c-1738f4e17fcf",
   "metadata": {},
   "source": [
    "## 3. Create a Collection in Milvus\n",
    "This code will drop the rag_docs collection if it exists, and then recreate it. This script should return the following text.\n",
    "```\n",
    "Status(code=0, message=)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2243d-f81e-4324-971c-44dcf68b3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.drop_collection(\"rag_docs\")\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True), # Primary key\n",
    "    FieldSchema(name=\"article_text\", dtype=DataType.VARCHAR, max_length=2500,),\n",
    "    FieldSchema(name=\"article_title\", dtype=DataType.VARCHAR, max_length=200,),\n",
    "    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=384),\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, \"rag collection schema\")\n",
    "\n",
    "wiki_collection = Collection(\"rag_docs\", schema)\n",
    "\n",
    "# Create index\n",
    "index_params = {\n",
    "        'metric_type':'L2',\n",
    "        'index_type':\"IVF_FLAT\",\n",
    "        'params':{\"nlist\":2048}\n",
    "}\n",
    "\n",
    "wiki_collection.create_index(field_name=\"vector\", index_params=index_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa147d48-dba2-4811-a9ba-47b6b1606690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Check that the Schema Exists\n",
    "utility.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd740-8bc5-44ae-a5c5-8c7daba82298",
   "metadata": {},
   "source": [
    "## 4. Insert Vectors into Milvus\n",
    "\n",
    "Here we read data from the watsonx.data table. We pull text chunks and titles from the database, being sure to separate them out into separate lists. We then vectorize using the `sentence-transformers/all-MiniLM-L6-v2` sentence transformer model. Learn more about Hugging Face sentence transformers here: [Sentence Transformers](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2).\n",
    "\n",
    "It is important we assemble the article text, article titles and vector embeddings into a `data` object. This object will be used to load the data into Milvus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b3cca-ca4a-4ca1-8497-5e8b22ef0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Wikipedia articles from watsonx.data using the engine we created earlier \n",
    "articles_df = %sql --pandas SELECT * from hive_data.rag_web.web_wikipedia\n",
    "\n",
    "# extract text + titles\n",
    "passages = articles_df['text'].tolist()\n",
    "passage_titles = articles_df['title'].tolist()\n",
    "\n",
    "# Create vector embeddings + data\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') # 384 dim\n",
    "passage_embeddings = model.encode(passages)\n",
    "\n",
    "basic_collection = Collection(\"rag_docs\") \n",
    "data = [\n",
    "    passages,\n",
    "    passage_titles,\n",
    "    passage_embeddings\n",
    "]\n",
    "out = basic_collection.insert(data)\n",
    "basic_collection.flush()  # Ensures data persistence\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c331f52-7d9d-4608-a719-01196eeae486",
   "metadata": {},
   "source": [
    "#### Check that the Collection has been Loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d084f-b8a1-4a88-b50e-5cd90f625035",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_collection = Collection(\"rag_docs\") \n",
    "basic_collection.load()\n",
    "basic_collection.num_entities "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830a9ea-4683-42be-8a83-a99629cab77e",
   "metadata": {},
   "source": [
    "## 5. Query Docs from Milvus through Semantic Search\n",
    "After gathering the data from Wikipedia and then vectorizing it and inserting into Milvus, we are now ready to perform queries against the vector database. We will use the `sentence-transformers/all-MiniLM-L6-v2` model to generate the query vector and then use Milvus to find the most similar vectors in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ffc8e8-383a-4798-bda5-8ddb95d86835",
   "metadata": {},
   "source": [
    "#### Create a Query Function\n",
    "The following function will be used to query the Milvus database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96297151-2f1f-411e-885b-bd8da0d01d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import(\n",
    "    Milvus,\n",
    "    IndexType,\n",
    "    Status,\n",
    "    connections,\n",
    "    FieldSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    ")\n",
    "\n",
    "def query_milvus(query, num_results=5):\n",
    "    # Vectorize query\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') # 384 dim\n",
    "    query_embeddings = model.encode([query])\n",
    "\n",
    "    # Search\n",
    "    search_params = {\n",
    "        \"metric_type\": \"L2\", \n",
    "        \"params\": {\"nprobe\": 5}\n",
    "    }\n",
    "    results = basic_collection.search(\n",
    "        data=query_embeddings, \n",
    "        anns_field=\"vector\", \n",
    "        param=search_params,\n",
    "        limit=num_results,\n",
    "        expr=None, \n",
    "        output_fields=['article_text'],\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d035f2a5-da27-49fe-9822-efa9c75b568b",
   "metadata": {},
   "source": [
    "#### Query Question\n",
    "Consider how climate change may relate to other industries and processes related to your business. Select one of the questions below to feed into Milvus query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336adfb9-9266-4378-9f6b-1d6dc62486eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_text = \"What can my company do to help fight climate change?\"\n",
    "#question_text = \"How do businesses negatively effect climate change?\"\n",
    "#question_text = \"What can a businesses do to have a positive effect on climate change?\"\n",
    "#question_text = \"How can a business reduce their carbon footprint?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9700c9b9-d27e-4eb8-a1bf-966e434a9be0",
   "metadata": {},
   "source": [
    "#### Search a Question in Milvus\n",
    "An embedding is made for the question being asked. It is then used to search for the most relevant chunks in Milvus. The top 3 related chunks are retrieved below and can be used for a large language prompt.\n",
    "\n",
    "The documents that best match the question are found in the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d200f-1cca-44fd-95e4-ace6c9c48e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_results = 3\n",
    "results = query_milvus(question_text, num_results)\n",
    "\n",
    "display_articles = []\n",
    "relevant_chunks  = []\n",
    "for i in range(num_results):\n",
    "    display_articles.append({\n",
    "        \"ID\"      : results[0].ids[i],\n",
    "        \"Distance\": results[0].distances[i],\n",
    "        # \"Article\" : re.sub(r\"^.*?\\. (.*$)\",r\"\\1\",results[0][i].entity.get('article_text'))\n",
    "        \"Article\" : re.sub(r\"^.*?\\. (.*\\.).*$\",r\"\\1\",results[0][i].entity.get('article_text'))        \n",
    "    })\n",
    "    relevant_chunks.append(re.sub(r\"^.*?\\. (.*\\.).*$\",r\"\\1\",results[0][i].entity.get('article_text')))\n",
    "\n",
    "df = pd.DataFrame.from_dict(display_articles).sort_values(\"Distance\",ascending=False)\n",
    "df.style.set_properties(**{'text-align': 'left'}).set_caption(question_text).set_table_styles([{\n",
    "    'selector': 'caption',\n",
    "    'props': [\n",
    "        ('color', 'blue'),\n",
    "        ('font-size', '20px')\n",
    "    ]\n",
    "}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "vscode": {"interpreter": {"hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"id": "31aa972b", "cell_type": "markdown", "source": "## RAG - Query Documents from watsonx.data Milvus in watsonx.ai (Web)", "metadata": {}, "attachments": {}}, {"id": "7f4e65e1-fd70-4fd5-8f58-e1410ac20661", "cell_type": "markdown", "source": "### Overview\nThis Jupyter Notebook provides a step-by-step guide on how to develop RAG using watsonx.data Milvus as a vector database (knowledge base). \nWe already have the documents stored as vector embeddings in Milvus, we are now ready to perform queries against the vector database.\nWe will use the same `sentence-transformers/all-MiniLM-L6-v2` embedding model to generate the query vector and then use Milvus to find the most similar vectors in the vector database.", "metadata": {"id": "7f4e65e1-fd70-4fd5-8f58-e1410ac20661"}}, {"id": "5bcaf226-f463-4b1c-8b04-c3692812d13c", "cell_type": "markdown", "source": "- Author: ahmad.muzaffar@ibm.com (APAC Ecosystem Technical Enablement).\n- This material has been adopted from material originally produced by Katherine Ciaravalli, Ken Bailey and George Baklarz.", "metadata": {"id": "5bcaf226-f463-4b1c-8b04-c3692812d13c"}}, {"id": "1c93b907-a23f-4f0a-a38e-8781a5cb36a0", "cell_type": "markdown", "source": "### 1. Install and import ibraries", "metadata": {"id": "1c93b907-a23f-4f0a-a38e-8781a5cb36a0"}}, {"id": "fcad48d0-cffa-4d17-980d-6b13d5c895c3", "cell_type": "code", "source": "# Install libraries\n!pip install grpcio==1.60.0 \n!pip install pymilvus\n!pip install ipython-sql==0.4.1\n!pip install sqlalchemy==1.4.46\n!pip install sqlalchemy==1.4.46 \"pyhive[presto]\"\n!pip install sentence_transformers\n!pip install python-dotenv\n!pip install ibm-cloud-sdk-core", "metadata": {"id": "4b4a3b36-3cf4-4535-a1b7-f0c1ec463fb8", "scrolled": true}, "outputs": [], "execution_count": null}, {"id": "685ccd46-293b-40cc-a79b-8679d20bc3b1", "cell_type": "code", "source": "# Import libraries\nimport os\n\nfrom dotenv import load_dotenv\nfrom ibm_cloud_sdk_core import IAMTokenManager\nfrom ibm_watson_studio_lib import access_project_or_space\nfrom ibm_watson_machine_learning.foundation_models import Model\nfrom ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n\nfrom sentence_transformers import SentenceTransformer\nfrom pymilvus import(\n    Milvus,\n    IndexType,\n    Status,\n    connections,\n    FieldSchema,\n    DataType,\n    Collection,\n    CollectionSchema,\n)\nfrom pymilvus import utility\n\nimport warnings\nwarnings.filterwarnings('ignore')", "metadata": {"id": "685ccd46-293b-40cc-a79b-8679d20bc3b1"}, "outputs": [], "execution_count": null}, {"id": "7399c5fd-4ba6-48d2-8cc2-5c2fe9f45f91", "cell_type": "markdown", "source": "### 2. Credential Settings\nTo streamline the credential setup process, we'll create a config.env file to consolidate all necessary credentials. \n1. Download the config.env file here (https://ibm.box.com/s/f1ku32ekh8jmfmievvxmpnwsvuttwa2x) and populate it with the required credentials listed below.\n2. Upload the config.env file into your watsonx.ai project.\n\nwatsonx.ai:\n- PROJECT_ID\n- ACCESS_TOKEN\n- IBM_CLOUD_URL (Example: https://us-south.ml.cloud.ibm.com)\n- API_KEY \n\nwatsonx.data:  \n- LH_HOST_NAME (Example: useast.services.cloud.techzone.ibm.com)\n- LH_PORT (From TechZone: Watsonx UI:xxxxx)\n\nMilvus:\n- MILVUS_HOST (Example: useast.services.cloud.techzone.ibm.com)\n- MILVUS_PORT (From TechZone: Milvus Port - Server:xxxxx)\n", "metadata": {"id": "7399c5fd-4ba6-48d2-8cc2-5c2fe9f45f91"}}, {"id": "5a839010", "cell_type": "code", "source": "# Credential settings\nwslib = access_project_or_space({\n        'token': '<YOUR WATSONX.AI PROJECT ACCESS TOKEN HERE>',\n        'project_id': '<YOUR WATSONX.AI PROJECT ID>'\n})\n\n# Download the config.env file and load the content\nwslib.download_file('config.env')\nload_dotenv('config.env')\n\n# Define connection variables\napi_key = os.getenv(\"API_KEY\", None)\nibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\", None) \nproject_id = os.getenv(\"PROJECT_ID\", None)\n\ncreds = {\n    \"url\": ibm_cloud_url,\n    \"apikey\": api_key \n}\n\naccess_token = IAMTokenManager(\n    apikey = api_key,\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n).get_token()", "metadata": {"ExecuteTime": {"end_time": "2023-06-23T05:07:05.048160Z", "start_time": "2023-06-23T05:07:05.038242Z"}, "id": "a81c504c-0108-4bf5-addb-f479f9a5ad39"}, "outputs": [], "execution_count": null}, {"id": "4350fd5a-617e-4e4d-ab70-57fb722deea5", "cell_type": "code", "source": "# Download the cert.crt file, .crt is a standard extension for certificate files, usually encoded in PEM (Privacy-Enhanced Mail) format, containing the public key and certificate information used in SSL/TLS communications to validate the identity of a server or client.\nwslib.download_file('cert.crt')", "metadata": {"id": "272055d3-0e46-46b8-9106-e80b3d23166c"}, "outputs": [], "execution_count": null}, {"id": "98b02b30-bcb6-4102-81d7-3c401db3f5d0", "cell_type": "markdown", "source": "### 3. Set Up Connection", "metadata": {"id": "98b02b30-bcb6-4102-81d7-3c401db3f5d0"}}, {"id": "16bb4816", "cell_type": "code", "source": "# Retrieve the credential information\nhost = os.getenv(\"MILVUS_HOST\", None)\nport = os.getenv(\"MILVUS_PORT\", None)\npassword = 'password'\nuser = 'ibmlhadmin'\nserver_pem_path = 'cert.crt'\n\n# Set connection\nconnections.connect(alias = 'default',\n                   host = host,\n                   port = port,\n                   user = user,\n                   password = password,\n                   server_pem_path = server_pem_path,\n                   server_name = 'watsonxdata',\n                   secure = True)", "metadata": {"id": "dca419eb-506a-42f2-b5b1-c85482730999"}, "outputs": [], "execution_count": null}, {"id": "9c7fe7e3-683c-42a0-b2df-fce8951c4eaa", "cell_type": "markdown", "source": "### 4. Load Milvus Collection ", "metadata": {"id": "9c7fe7e3-683c-42a0-b2df-fce8951c4eaa"}}, {"id": "ddb92562-d646-4898-93a0-a92c82b0a9e1", "cell_type": "code", "source": "# Check collection name\nutility.list_collections()", "metadata": {"id": "ddb92562-d646-4898-93a0-a92c82b0a9e1"}, "outputs": [], "execution_count": null}, {"id": "11445f73-5c48-4921-ba3b-e442db773ff8", "cell_type": "code", "source": "# Load collection\nbasic_collection = Collection(\"rag_docs\")      \nbasic_collection.load()", "metadata": {"id": "11445f73-5c48-4921-ba3b-e442db773ff8"}, "outputs": [], "execution_count": null}, {"id": "befd1461-f38c-4c4e-9abf-353dea9aa7fa", "cell_type": "markdown", "source": "### 5. Query Milvus", "metadata": {"id": "befd1461-f38c-4c4e-9abf-353dea9aa7fa"}}, {"id": "68393a88-2bf4-4c9a-8417-7eaa461736f6", "cell_type": "code", "source": "# Query function that vectorize query, search documents via Semantic Search and return the search result\ndef query_milvus(query, num_results):\n    \n    # Vectorize query\n    model = SentenceTransformer('sentence-transformers/all-minilm-l12-v2') # 384 dim\n    query_embeddings = model.encode([query])\n\n    # Search\n    search_params = {\n        \"metric_type\": \"L2\", \n        \"params\": {\"nprobe\": 5}\n    }\n    results = basic_collection.search(\n        data=query_embeddings, \n        anns_field=\"vector\", \n        param=search_params,\n        limit=num_results,\n        expr=None, \n        output_fields=['article_text'],\n    )\n    return results", "metadata": {"id": "68393a88-2bf4-4c9a-8417-7eaa461736f6"}, "outputs": [], "execution_count": null}, {"id": "9dc2a311", "cell_type": "markdown", "source": "### 6. Prompt watsonx.ai LLM with Context (Query Results)", "metadata": {}}, {"id": "2baf810c-c791-4497-8cb7-b1f77debdb74", "cell_type": "code", "source": "# Sample query on topics related to how climate change may relate to other industries and processes related to your business\n\nquestion_text = \"How do businesses negatively affect climate change?\"\n#question_text = \"What can a businesses do to have a positive effect on climate change?\"\n#question_text = \"How can a business reduce their carbon footprint?\"\n\n# Irrelevant sample query\n#question_text = \"How much is the processing fee for credit card replacement?\"", "metadata": {"id": "be694743-a243-4aff-9bb8-a1ba0de74e47"}, "outputs": [], "execution_count": null}, {"id": "c6f193cd-ecd8-4128-809c-d3eb280daff6", "cell_type": "code", "source": "# Define a distance threshold (adjust based on your data and model)\nthreshold = 1.5  # Example value, tune it as necessary\nprint(f\"Threshold value is {threshold}.\")\n\nnum_results = 3\nresults = query_milvus(question_text, num_results)\n\nrelevant_chunks = []\nfor i in range(num_results):\n    id = results[0].ids[i]\n    distance = results[0].distances[i]\n    \n    # Filter results based on the distance threshold\n    if distance <= threshold:\n        print(f\"id: {id}\")\n        print(f\"distance: {distance}\")\n        \n        text = results[0][i].entity.get('article_text')\n        relevant_chunks.append(text)\n        \n        print(f\"Relevant Chunk {i+1}:\")\n        print(text)\n        print(\"\\n\")\n    else:\n        print(f\"Result {i+1} skipped due to high distance ({distance}).\")\n        relevant_chunks = \"NO RELEVANT CONTEXT FOUND\"", "metadata": {"id": "c6f193cd-ecd8-4128-809c-d3eb280daff6"}, "outputs": [], "execution_count": null}, {"id": "87c05239-5a10-43dc-a088-c1ded94c8a3a", "cell_type": "code", "source": "print(relevant_chunks)", "metadata": {"id": "87c05239-5a10-43dc-a088-c1ded94c8a3a"}, "outputs": [], "execution_count": null}, {"id": "4470238c", "cell_type": "code", "source": "# This function construct a prompt template\ndef make_prompt(context, question_text):\n    return (f\"{context}\\n\\nPlease answer a question using this text. \"\n          + f\"If there is no text found, say \\\"unanswerable\\\".\"\n          + f\"\\n\\nQuestion: {question_text}\")\n\n# Build prompt w/ Milvus results\n# Embed retrieved passages(context) and user question into into prompt text\n\n#context = \"\\n\\n\".join(relevant_chunks)\ncontext = \"\".join(relevant_chunks)\n\nprompt = make_prompt(context, question_text)\n\nprint(prompt)", "metadata": {"id": "924aac45-1a17-4ecd-9908-1d606e2db6f0"}, "outputs": [], "execution_count": null}, {"id": "a6af4422-dc97-4412-9c18-ec63ae78311f", "cell_type": "markdown", "source": "### 7. Set up LLM, parameters and inferencing", "metadata": {"id": "a6af4422-dc97-4412-9c18-ec63ae78311f"}}, {"id": "7dcd518e", "cell_type": "code", "source": "# Model inferencing parameters\nparams = {\n        GenParams.DECODING_METHOD: \"greedy\",\n        GenParams.MIN_NEW_TOKENS: 1,\n        GenParams.MAX_NEW_TOKENS: 500,\n        GenParams.TEMPERATURE: 0,\n}\n\n# LLM\nmodel = Model(\n        model_id='ibm/granite-13b-chat-v2', \n        params=params, credentials=creds, \n        project_id=project_id\n)\n\n# Inferencing\nresponse = model.generate_text(prompt)\nprint(f\"Question: {question_text}{response}\")", "metadata": {"id": "b6b3df7b-ae2e-49d0-b40f-a072f3d3d165"}, "outputs": [], "execution_count": null}]}
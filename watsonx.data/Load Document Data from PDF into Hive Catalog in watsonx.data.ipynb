{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acbc29d5-76b4-4c9c-abdd-eaf8b4c00ebf",
   "metadata": {},
   "source": [
    "# Load Document Data from PDF into Hive Catalog in watsonx.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a6903-4e80-416a-a4f5-082906630f89",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This Jupyter Notebook provides a step-by-step guide on how to prepare PDF document data for RAG using Milvus as a vector database (in watsonx.data).\n",
    "\n",
    "In this notebook, as the first step, we will prepare document data from the PDF files and populate it into the Hive Catalog (in watsonx.data). Here are the steps:\r",
    "1. Install and import libraries.\n",
    "2. Connect to watsonx.data\n",
    "3. Create Schema and Table in Hive Catalog.\n",
    "4. Chunk the PDF documents and load into Hive Table.\n",
    "5. Check the loaded documents data in Hive Table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42caa0db-566a-4092-af10-7636456504b3",
   "metadata": {},
   "source": [
    "- Author: ahmad.muzaffar@ibm.com (APAC Ecosystem Technical Enablement).\n",
    "- This material has been adopted from material originally produced by Katherine Ciaravalli, Ken Bailey and George Baklarz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae50a6",
   "metadata": {},
   "source": [
    "## 1. Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d56fa0f-0d4a-4323-b212-a28eb64b91cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "!pip install ipython-sql==0.4.1\n",
    "!pip install sqlalchemy==1.4.46\n",
    "!pip install pyhive[presto]\n",
    "!pip install python-dotenv\n",
    "!pip install grpcio==1.60.0\n",
    "!pip install langchain\n",
    "!pip install pandas==2.1.4\n",
    "!pip install langchain_community\n",
    "!pip install PyPDF2\n",
    "!pip install pymilvus\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb391fb-2f12-427a-8ea4-fec739780dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import ssl\n",
    "import urllib3\n",
    "import os\n",
    "\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning) # disable https warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b70849-6f29-41dd-ad9d-2ea7acffd9bd",
   "metadata": {},
   "source": [
    "## 2. Connect to watsonx.data\n",
    "The following code will use the Presto Magic commmands to load data in watsonx.data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f6cde-bd30-4987-b5f8-2c6ebda05c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run presto.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861981f3-f699-4009-9c7a-ec645899e776",
   "metadata": {},
   "source": [
    "The connection details should not change unless you are attempting to run this script from a Jupyter environment that is outside of the developer system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "   connect\n",
    "   userid=ibmlhadmin\n",
    "   password=password\n",
    "   hostname=watsonxdata\n",
    "   port=8443\n",
    "   catalog=tpch\n",
    "   schema=tiny\n",
    "   certfile=/certs/lh-ssl-ts.crt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e723dc88-a7a3-4931-aa16-eb33e679a1be",
   "metadata": {},
   "source": [
    "## 3. Create Schema and Table in Hive Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54ddf5-e999-4912-a1c2-652a6951ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS hive_data.rag_pdf.pdf_watsonx;\n",
    "DROP SCHEMA IF EXISTS hive_data.rag_pdf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87869784-ae9d-4174-b245-c3f763313226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step will delete any existing data in the rag_web bucket. \n",
    "# A DROP table command does not remove the files in the bucket. \n",
    "# You may see error messages displayed if no data or bucket exists.\n",
    "\n",
    "minio_host    = \"watsonxdata\"\n",
    "minio_port    = \"9000\"\n",
    "hive_host     = \"watsonxdata\"\n",
    "hive_port     = \"9083\"\n",
    "\n",
    "hive_id           = None\n",
    "hive_password     = None\n",
    "minio_access_key  = None\n",
    "minio_secret_key  = None\n",
    "keystore_password = None\n",
    "\n",
    "try:\n",
    "    with open('/certs/passwords') as fd:\n",
    "        certs = fd.readlines()\n",
    "    for line in certs:\n",
    "        args = line.split()\n",
    "        if (len(args) >= 3):\n",
    "            system   = args[0].strip()\n",
    "            user     = args[1].strip()\n",
    "            password = args[2].strip()\n",
    "            if (system == \"Minio\"):\n",
    "                minio_access_key = user\n",
    "                minio_secret_key = password\n",
    "            elif (system == \"Thrift\"):\n",
    "                hive_id = user\n",
    "                hive_password = password\n",
    "            elif (system == \"Keystore\"):\n",
    "                keystore_password = password\n",
    "            else:\n",
    "                pass\n",
    "except Error as e:\n",
    "    print(\"Certificate file with passwords could not be found\")\n",
    "\n",
    "%system mc alias set watsonxdata http://{minio_host}:{minio_port} {minio_access_key} {minio_secret_key}\n",
    "\n",
    "%system mc rm --recursive --force watsonxdata/hive-bucket/rag_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40465ab-1f2c-469a-804f-425d9abb707d",
   "metadata": {},
   "source": [
    "### Create Schema (rag_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54920c5b-5fa1-43d4-aaae-2488ba654077",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE SCHEMA IF NOT EXISTS \n",
    "  hive_data.rag_pdf \n",
    "WITH (location = 's3a://hive-bucket/rag_pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd67bfc-ffee-4bbe-8862-451e0e60b6fd",
   "metadata": {},
   "source": [
    "### Create Table (pdf_watsonx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b8bc4-a663-40af-b4af-c79650ce3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE hive_data.rag_pdf.pdf_watsonx\n",
    "  (\n",
    "    \"id\" varchar,\n",
    "    \"text\" varchar,\n",
    "    \"title\" varchar  \n",
    "  )\n",
    "WITH \n",
    "  (\n",
    "  format = 'PARQUET',\n",
    "  external_location = 's3a://hive-bucket/rag_pdf' \n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c109b-5f1b-4f80-9525-0f4daa4755e8",
   "metadata": {},
   "source": [
    "## 4. Chunk the PDF documents and load into Hive Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae50b61-c173-4145-852f-0f7704349a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the document filename into a list\n",
    "pdf_files=['DB2 and DB2 Warehouse on Cloud [TechTalks].PDF',\n",
    "          'IBM Watsonx.Data [TechTalks].PDF',\n",
    "          'IBM watsonx.data Milvus Vector Database Competitive - Mar 2024 Final.pdf'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490c3b1-3069-4917-9a87-9bf54e86e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter for chunking\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 50   \n",
    "\n",
    "# Use text splitter function by LangChain\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=CHUNK_SIZE,\n",
    "            chunk_overlap=CHUNK_OVERLAP\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b49b8-71ad-4627-9f84-7ea79be2ae4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an empty string for text\n",
    "all_data = ''\n",
    "\n",
    "# Initialize the index counter\n",
    "index_counter = 1  \n",
    "\n",
    "# For each pdf file, we conduct text extraction, processing, chunking and insertion into Hive table\n",
    "if pdf_files:\n",
    "    for pdf in pdf_files:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf)\n",
    "        \n",
    "        # Extract text from each page\n",
    "        for page in pdf_reader.pages:\n",
    "            text = page.extract_text()\n",
    "            all_data += text\n",
    "            \n",
    "        # Escapes special characters and replaces newlines with spaces\n",
    "        all_data = all_data.replace(\"'\", \"''\").replace(\"%\", \"%%\").replace(\"\\n\", \" \")\n",
    "\n",
    "        # Chunking data\n",
    "        texts = text_splitter.split_text(all_data)\n",
    "       \n",
    "        # Insert data\n",
    "        for chunk in texts:\n",
    "            insert_stmt = f\"insert into hive_data.rag_pdf.pdf_watsonx values ('{index_counter}', '{chunk}', '{pdf}')\"\n",
    "            %sql --quiet {insert_stmt}\n",
    "            print(f\"{pdf} chunk {index_counter} Inserted.\")  \n",
    "            index_counter += 1  # Increment the index counter after each insertion\n",
    "\n",
    "print('Data insertion completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a347b2-7206-4d1c-bd79-e2793a04ba8d",
   "metadata": {},
   "source": [
    "## 5. Check the loaded documents data in Hive Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "   SELECT * FROM hive_data.rag_pdf.pdf_watsonx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
